# ğŸ¤– Agent QA í…ŒìŠ¤íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ

LangSmith/LangChain Hub ê¸°ë°˜ì˜ AI Agent QA í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê´€ë¦¬ ë° GPT-4o ìë™ í‰ê°€ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

- ğŸ“‹ **í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê´€ë¦¬**: Excel íŒŒì¼ì„ LangSmith ë°ì´í„°ì…‹ìœ¼ë¡œ ìë™ ë³€í™˜ ë° ê´€ë¦¬
- ğŸ¤– **GPT-4o ë‹µë³€ ìƒì„±**: ì§ˆë¬¸ì— ëŒ€í•œ ì‹¤ì œ GPT-4o ë‹µë³€ ìë™ ìƒì„±
- âš–ï¸ **LLM-as-Judge í‰ê°€**: GPT-4o Judgeë¥¼ ì‚¬ìš©í•œ 0-5ì  ì •í™•ì„± ìë™ í‰ê°€
- ğŸ’¾ **ê²°ê³¼ ì €ì¥**: ëª¨ë“  í‰ê°€ ê²°ê³¼ë¥¼ LangSmith ë°ì´í„°ì…‹ì— ì²´ê³„ì  ì €ì¥
- ğŸ“ˆ **íˆìŠ¤í† ë¦¬ ì¶”ì **: ë™ì¼ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ì˜ ì—¬ëŸ¬ ì‹¤í–‰ ê²°ê³¼ ëˆ„ì  ì¶”ì 
- ğŸ”§ **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: LangChain Hubë¥¼ í†µí•œ ì¤‘ì•™ì§‘ì¤‘ì‹ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
- ğŸŒ **ì›¹ ì¸í„°í˜ì´ìŠ¤**: Gradio ê¸°ë°˜ ì‚¬ìš©ì ì¹œí™”ì  ì›¹ UI
- ğŸ“Š **ì‹œê°í™”**: í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ë° ë¹„êµ ë¶„ì„
- âš™ï¸ **ì„œë²„ ê´€ë¦¬**: ì›¹ ì„œë²„ ì‹œì‘/ì¤‘ì§€/ìƒíƒœ ê´€ë¦¬ ë„êµ¬

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°

```
new_project/
â”œâ”€â”€ ğŸ“Š ë°ì´í„° ê´€ë¦¬
â”‚   â”œâ”€â”€ dataset_manager.py      # LangSmith ë°ì´í„°ì…‹ ê´€ë¦¬ ë° í‰ê°€ ì‹œìŠ¤í…œ
â”‚   â”œâ”€â”€ real_implementation.py  # ì‹¤ì œ GPT-4o ì§ˆì˜ ë° í‰ê°€ êµ¬í˜„
â”‚   â””â”€â”€ TestCase.xlsx          # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ Excel íŒŒì¼
â”‚
â”œâ”€â”€ ğŸ”§ ì‹œìŠ¤í…œ ê´€ë¦¬
â”‚   â”œâ”€â”€ prompt_manager.py       # LangChain Hub í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
â”‚   â”œâ”€â”€ server_manager.py       # ì›¹ ì„œë²„ ê´€ë¦¬ ë„êµ¬
â”‚   â””â”€â”€ run.py                 # í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ ğŸŒ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ web_interface.py        # Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤
â”‚   â””â”€â”€ visualization.py       # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ë„êµ¬
â”‚
â”œâ”€â”€ ğŸ“š ì˜ˆì‹œ ë° ë¬¸ì„œ
â”‚   â”œâ”€â”€ example_usage.py        # ì‚¬ìš© ì˜ˆì‹œ ë° ë°ëª¨
â”‚   â””â”€â”€ README.md              # ì´ íŒŒì¼
â”‚
â””â”€â”€ ğŸ“ ê¸°íƒ€
    â”œâ”€â”€ __init__.py            # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
    â””â”€â”€ server_7861.log        # ì„œë²„ ë¡œê·¸ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„± (.env íŒŒì¼ì„ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±)
# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY=your_openai_api_key_here
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=your_project_name
```

### 2. í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©

```bash
# ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
python new_project/run.py
```

ì‹¤í–‰í•˜ë©´ ë‹¤ìŒ ë©”ë‰´ê°€ í‘œì‹œë©ë‹ˆë‹¤:
1. **ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰** - Gradio ì›¹ UI ì‹œì‘
2. **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬** - LangChain Hub í”„ë¡¬í”„íŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸
3. **ë°ì´í„°ì…‹ì— TestCase ìƒì„±** - Excel â†’ LangSmith ì €ì¥
4. **Judge í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ í›„ í‰ê°€** - GPT-4o í‰ê°€ ì‹¤í–‰
5. **ì„œë²„ ê´€ë¦¬** - ì›¹ ì„œë²„ ì‹œì‘/ì¤‘ì§€/ìƒíƒœ í™•ì¸

### 3. ì›¹ ì¸í„°í˜ì´ìŠ¤ ì§ì ‘ ì‹¤í–‰

```bash
python new_project/web_interface.py
```

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:7861`ìœ¼ë¡œ ì ‘ì†í•˜ì—¬ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

## ğŸ“– ì‚¬ìš©ë²•

### ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°

1. **í”„ë¡¬í”„íŠ¸ ì¤€ë¹„**: `accuracy_judge_prompt`ë¥¼ LangChain Hubì— ìƒì„±
2. **í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¤€ë¹„**: `TestCase.xlsx` íŒŒì¼ì— case_id, question ì»¬ëŸ¼ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì‘ì„±
3. **ë°ì´í„° ì €ì¥**: Excel íŒŒì¼ì„ LangSmith `Agent_QA_Scenario` ë°ì´í„°ì…‹ì— ì €ì¥
4. **í‰ê°€ ì‹¤í–‰**: GPT-4oë¡œ ë‹µë³€ ìƒì„± í›„ Judgeë¡œ í‰ê°€í•˜ì—¬ ê²°ê³¼ ì €ì¥
5. **ê²°ê³¼ í™•ì¸**: ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ í‰ê°€ ê²°ê³¼ ë° íˆìŠ¤í† ë¦¬ í™•ì¸

### í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©

```python
from dataset_manager import AgentQADatasetManager

# ë°ì´í„°ì…‹ ë§¤ë‹ˆì € ì´ˆê¸°í™”
manager = AgentQADatasetManager()

# í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì¶”ê°€
test_case_id = manager.add_test_case(
    question="ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?",
    expected_answer="ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤."
)

# ë‹µë³€ í‰ê°€
result = manager.evaluate_answer(
    test_case_id=test_case_id,
    question="ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?",
    actual_answer="ì„œìš¸ì…ë‹ˆë‹¤.",
    model_used="gpt-4o"
)

print(f"í‰ê°€ ì ìˆ˜: {result.judge_accuracy_score}/5")
print(f"í‰ê°€ ê·¼ê±°: {result.judge_reasoning}")
```

### ì‹¤ì œ GPT-4o í‰ê°€ ì‹œìŠ¤í…œ ì‚¬ìš©

```python
from real_implementation import RealAgentQASystem

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
system = RealAgentQASystem()

# Excelì—ì„œ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë¡œë“œ
testcases = system.load_testcases_from_excel("TestCase.xlsx")

# LangSmithì— ì €ì¥
system.save_testcases_to_langsmith(testcases)

# GPT-4oë¡œ ë‹µë³€ ìƒì„± ë° í‰ê°€
stored_testcases = system.get_testcases_from_langsmith()
for tc in stored_testcases:
    answer = system.generate_answer_with_gpt4o(tc['question'])
    judge_result = system.judge_answer_with_gpt4o(tc['question'], answer)
    print(f"{tc['case_id']}: {judge_result['score']}/5ì ")
```

## ğŸ¯ ë°ì´í„° êµ¬ì¡°

### LangSmith ë°ì´í„°ì…‹

1. **Agent_QA_Scenario**: í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ì €ì¥
   - inputs: `{"question": "ì§ˆë¬¸ ë‚´ìš©"}`
   - metadata: `{"case_id": "TC_001", "source": "TestCase.xlsx"}`

2. **Agent_QA_Scenario_Judge_Result**: í‰ê°€ ê²°ê³¼ ì €ì¥
   - inputs: `{"input": "ì§ˆë¬¸ ë‚´ìš©"}`
   - outputs: `{"answer": "LLM ë‹µë³€", "judge_accuracy_score": 4, "judge_reasoning": "í‰ê°€ ê·¼ê±°"}`
   - metadata: `{"case_id": "TC_001", "model_used": "gpt-4o"}`

3. **Agent_QA_Scenario_Judge_History**: íˆìŠ¤í† ë¦¬ ëˆ„ì  ì €ì¥
   - outputs: `{"scores": [4, 5, 3], "answers": [...], "reasons": [...], "timestamps": [...]}`

### í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ (TestCase)
```python
@dataclass
class TestCase:
    id: str                    # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ê³ ìœ  ID
    question: str              # ì§ˆë¬¸
    expected_answer: str       # ê¸°ëŒ€ ë‹µë³€ (ì„ íƒì‚¬í•­)
    created_at: str           # ìƒì„± ì‹œê°„
```

### í‰ê°€ ê²°ê³¼ (EvaluationResult)
```python
@dataclass
class EvaluationResult:
    test_case_id: str          # í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ID
    execution_id: str          # ì‹¤í–‰ ê³ ìœ  ID
    question: str              # ì§ˆë¬¸
    actual_answer: str         # ì‹¤ì œ ë‹µë³€
    judge_accuracy_score: float # ì •í™•ì„± ì ìˆ˜ (0-5)
    judge_reasoning: str       # í‰ê°€ ê·¼ê±°
    execution_time: str        # ì‹¤í–‰ ì‹œê°„
    model_used: str           # ì‚¬ìš©ëœ ëª¨ë¸ëª…
```

## ğŸ“Š í‰ê°€ ê¸°ì¤€

LLM-as-JudgeëŠ” ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ 0-5ì  ì‚¬ì´ë¡œ í‰ê°€í•©ë‹ˆë‹¤:

- **5ì **: ì™„ë²½íˆ ì •í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€
- **4ì **: ëŒ€ë¶€ë¶„ ì •í™•í•˜ë©° ì•½ê°„ì˜ ë¶€ì¡±í•¨ì´ ìˆìŒ  
- **3ì **: ê¸°ë³¸ì ìœ¼ë¡œ ì •í™•í•˜ë‚˜ ì¤‘ìš”í•œ ì •ë³´ê°€ ëˆ„ë½ë¨
- **2ì **: ë¶€ë¶„ì ìœ¼ë¡œ ì •í™•í•˜ë‚˜ ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•í•œ ì •ë³´ í¬í•¨
- **1ì **: ëŒ€ë¶€ë¶„ ë¶€ì •í™•í•˜ë‚˜ ì¼ë¶€ ê´€ë ¨ëœ ì •ë³´ í¬í•¨
- **0ì **: ì™„ì „íˆ ë¶€ì •í™•í•˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” ë‹µë³€

## ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤ ê¸°ëŠ¥

### 1. ë©”ì¸ ì‹¤í–‰ íƒ­
- TestCase.xlsx â†’ LangSmith ì €ì¥
- GPT-4o í‰ê°€ ì‹¤í–‰/ì €ì¥
- ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°

### 2. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ íƒ­
- accuracy_judge_prompt ìƒì„±/ì—…ë°ì´íŠ¸
- í˜„ì¬ ë²„ì „ ì¡°íšŒ
- LangChain Hub ì—°ë™

### 3. í‰ê°€ ê²°ê³¼ íƒ­
- ìµœì‹  í‰ê°€ ê²°ê³¼ í…Œì´ë¸”
- ìš”ì•½ í†µê³„ (í‰ê· , ìµœê³ , ìµœì € ì ìˆ˜)
- ì ìˆ˜ ë¶„í¬ í˜„í™©
- LangSmith ë°ì´í„°ì…‹ ì§ì ‘ ë§í¬

### 4. íˆìŠ¤í† ë¦¬ ì¡°íšŒ íƒ­
- case_idë³„ íˆìŠ¤í† ë¦¬ ì„ íƒ
- ì ìˆ˜ íƒ€ì„ë¼ì¸ ê·¸ë˜í”„
- ìƒì„¸ íˆìŠ¤í† ë¦¬ í…Œì´ë¸”
- Trace ë§í¬ ì œê³µ

### 5. ì„œë²„ ê´€ë¦¬ íƒ­
- ì„œë²„ ìƒíƒœ í™•ì¸
- ì„œë²„ ì¤‘ì§€ ê¸°ëŠ¥
- ì‹¤ì‹œê°„ ìƒíƒœ ì—…ë°ì´íŠ¸

### 6. ì‹œìŠ¤í…œ ì •ë³´ íƒ­
- ì‹œìŠ¤í…œ ê°œìš” ë° ì‚¬ìš©ë²•
- í‰ê°€ ê¸°ì¤€ ì„¤ëª…
- ì—°ë™ ì„œë¹„ìŠ¤ ì •ë³´

## ğŸ”§ ê³ ê¸‰ ì„¤ì •

### ì»¤ìŠ¤í…€ Judge ëª¨ë¸
```python
from langchain_openai import ChatOpenAI

manager = AgentQADatasetManager()
manager.judge_llm = ChatOpenAI(model="gpt-4", temperature=0)
```

### í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
```python
from prompt_manager import PromptManager

pm = PromptManager()
# í”„ë¡¬í”„íŠ¸ ìƒì„±/ì—…ë°ì´íŠ¸
pm.create_or_update_accuracy_judge_prompt()
# í˜„ì¬ ë²„ì „ ì¡°íšŒ
pm.list_prompts()
```

### ì„œë²„ ê´€ë¦¬
```python
from server_manager import ServerManager

sm = ServerManager(port=7861)
sm.start_server()    # ì„œë²„ ì‹œì‘
sm.server_status()   # ìƒíƒœ í™•ì¸
sm.stop_server()     # ì„œë²„ ì¤‘ì§€
```

## ğŸ“ˆ ì‹œê°í™” ê¸°ëŠ¥

### í…ŒìŠ¤íŠ¸ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
```python
from visualization import TestHistoryVisualizer

visualizer = TestHistoryVisualizer()

# ë‹¨ì¼ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ íƒ€ì„ë¼ì¸
fig = visualizer.create_single_testcase_timeline(history, test_case_id)
fig.show()

# ì „ì²´ ë¹„êµ ëŒ€ì‹œë³´ë“œ
dashboard = visualizer.create_history_comparison(all_histories)
dashboard.show()

# ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
summary = visualizer.generate_summary_report(test_case_histories)
```

## ğŸ” ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ê¸°ë³¸ QA í…ŒìŠ¤íŠ¸
1. `TestCase.xlsx`ì— ì§ˆë¬¸ ì‘ì„±
2. ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ "TestCase.xlsx â†’ LangSmith ì €ì¥" ì‹¤í–‰
3. "GPT-4o í‰ê°€ ì‹¤í–‰/ì €ì¥" ì‹¤í–‰
4. í‰ê°€ ê²°ê³¼ íƒ­ì—ì„œ ê²°ê³¼ í™•ì¸

### ì‹œë‚˜ë¦¬ì˜¤ 2: í”„ë¡œê·¸ë˜ë° ë°©ì‹ ì‚¬ìš©
```python
# ì˜ˆì‹œ ì½”ë“œ ì‹¤í–‰
python new_project/example_usage.py
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì„œë²„ ê´€ë¦¬
```bash
# ì„œë²„ ì‹œì‘
python new_project/server_manager.py start

# ì„œë²„ ìƒíƒœ í™•ì¸
python new_project/server_manager.py status

# ì„œë²„ ì¤‘ì§€
python new_project/server_manager.py stop
```

## ğŸ› ï¸ í™•ì¥ ê°€ëŠ¥ì„±

### ì»¤ìŠ¤í…€ í‰ê°€ ë©”íŠ¸ë¦­ ì¶”ê°€
- `real_implementation.py`ì˜ `judge_answer_with_gpt4o` ë©”ì„œë“œ í™•ì¥
- ì¶”ê°€ í‰ê°€ ê¸°ì¤€ (ê´€ë ¨ì„±, ì™„ì „ì„± ë“±) êµ¬í˜„

### ë°°ì¹˜ í‰ê°€ ê¸°ëŠ¥
- ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ ë™ì‹œ ì²˜ë¦¬
- ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•œ ì„±ëŠ¥ ìµœì í™”

### ë‹¤ì–‘í•œ ëª¨ë¸ ì§€ì›
- GPT-4o ì™¸ ë‹¤ë¥¸ LLM ëª¨ë¸ ì—°ë™
- ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ë¶„ì„

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

1. **API í‚¤ ì˜¤ë¥˜**
   - `.env` íŒŒì¼ì˜ API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
   - LangSmith ê³„ì • ìƒíƒœ ë° í”„ë¡œì íŠ¸ ì„¤ì • í™•ì¸

2. **ë°ì´í„°ì…‹ ì ‘ê·¼ ì˜¤ë¥˜**
   - LangSmith í”„ë¡œì íŠ¸ ê¶Œí•œ í™•ì¸
   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸

3. **í‰ê°€ ì‹¤íŒ¨**
   - OpenAI API í•œë„ ë° í¬ë ˆë”§ í™•ì¸
   - Judge í”„ë¡¬í”„íŠ¸ ì„¤ì • í™•ì¸

4. **ì›¹ ì¸í„°í˜ì´ìŠ¤ ì˜¤ë¥˜**
   - í¬íŠ¸ 7861ì´ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸
   - ì„œë²„ ë¡œê·¸ íŒŒì¼ í™•ì¸ (`server_7861.log`)

### ë¡œê·¸ í™•ì¸
```bash
# ì„œë²„ ë¡œê·¸ í™•ì¸
python new_project/server_manager.py logs

# ë””ë²„ê·¸ ëª¨ë“œ ì‹¤í–‰
python -c "
import logging
logging.basicConfig(level=logging.DEBUG)
from dataset_manager import AgentQADatasetManager
manager = AgentQADatasetManager()
"
```

## ğŸ”— ì—°ë™ ì„œë¹„ìŠ¤

- **LangSmith**: ë°ì´í„°ì…‹ ê´€ë¦¬, ì‹¤í–‰ ì¶”ì , í‰ê°€ ê²°ê³¼ ì €ì¥
- **LangChain Hub**: ì¤‘ì•™ì§‘ì¤‘ì‹ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ë° ë²„ì „ ê´€ë¦¬
- **OpenAI GPT-4o**: ë‹µë³€ ìƒì„± ë° LLM-as-Judge í‰ê°€
- **Gradio**: ì›¹ ì¸í„°í˜ì´ìŠ¤ í”„ë ˆì„ì›Œí¬
- **Plotly**: ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork í”„ë¡œì íŠ¸
2. Feature ë¸Œëœì¹˜ ìƒì„± (`git checkout -b feature/AmazingFeature`)
3. ë³€ê²½ì‚¬í•­ ì»¤ë°‹ (`git commit -m 'Add some AmazingFeature'`)
4. ë¸Œëœì¹˜ì— Push (`git push origin feature/AmazingFeature`)
5. Pull Request ìƒì„±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤.

## ğŸ™‹â€â™‚ï¸ ì§€ì›

ë¬¸ì œê°€ ìˆê±°ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì´ ìˆìœ¼ì‹œë©´ GitHub Issuesë¥¼ í†µí•´ ë¬¸ì˜í•´ì£¼ì„¸ìš”.

---

**Happy Testing! ğŸ‰**